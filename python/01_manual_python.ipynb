{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python manual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"contents\"></a>\n",
    "# Contents\n",
    "\n",
    "- [Configuration](#conf)\n",
    "- [Os](#os)\n",
    "- [Sys](#sys)\n",
    "- [Pdb](#pdb)\n",
    "- [String](#string)\n",
    "- [Regex](#regex)\n",
    "- [Random](#rnd)\n",
    "- [Time](#time)\n",
    "- [Datetime](#datetime)\n",
    "    - [time objects](#timeobj)\n",
    "    - [date objects](#dateobj)\n",
    "    - [datetime objects](#datetimeobj)\n",
    "- [Dateutil](#dateutil)\n",
    "- [Zipfile](#zipfile)\n",
    "- [Argparse](#argparse)\n",
    "- [Subprocess](#subproc)\n",
    "- [Multiprocessing](#multiproc)\n",
    "- [Unittest](#unittest)\n",
    "- [A/B Tests](#ab)\n",
    "- [Errors](#error)\n",
    "- [Data types](#data)\n",
    "    - [set](#set)\n",
    "    - [list](#list)\n",
    "    - [tuple](#tuple)\n",
    "    - [dictionary](#dictionary)\n",
    "- [Functions](#fnc)\n",
    "- [Objects](#obj)\n",
    "- [I/O](#io)\n",
    "    - [create](#create)\n",
    "    - [write](#write)\n",
    "    - [read](#read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"conf\"></a>\n",
    "# Configuration\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"imports\"></a>\n",
    "### imports\n",
    "\n",
    "Imports are always put at the top of the file, just after any module comments and docstrings, and before module globals and constants.  \n",
    "Imports should usually be on separate lines.  \n",
    "Imports should be grouped in the following order:\n",
    "- standard library imports\n",
    "- related third party imports\n",
    "- local application/library specific imports\n",
    "\n",
    "You should put a blank line between each group of imports.\n",
    "\n",
    "**References**\n",
    "- python standard library https://docs.python.org/3/library/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T08:18:23.476710Z",
     "start_time": "2022-10-04T08:18:21.490437Z"
    }
   },
   "outputs": [],
   "source": [
    "# first you should import python standard library modules\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import pdb\n",
    "import json\n",
    "import pytz\n",
    "import time\n",
    "import string\n",
    "import inspect\n",
    "import zipfile\n",
    "import unittest\n",
    "import random as rnd\n",
    "import datetime as dt\n",
    "import multiprocessing\n",
    "from operator import itemgetter\n",
    "from itertools import groupby, chain\n",
    "\n",
    "# then you should import third parties packages that you have installed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "from pympler import asizeof\n",
    "from IPython.display import display, HTML, Image\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# finally you should import Local application/library specific imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"env\"></a>\n",
    "### environment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T08:18:24.472784Z",
     "start_time": "2022-10-04T08:18:23.482617Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "display(HTML('<style>.container { width:90% !important; }</style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T08:18:24.534586Z",
     "start_time": "2022-10-04T08:18:24.513006Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'Running notebook with Conda Env {os.environ[\"CONDA_DEFAULT_ENV\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"global\"></a>\n",
    "### global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T08:18:24.550444Z",
     "start_time": "2022-10-04T08:18:24.541611Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = 'C:\\\\Users\\\\pgreselin\\\\OneDrive\\\\Python'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"install\"></a>\n",
    "### dependencies installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T08:18:44.006736Z",
     "start_time": "2022-10-04T08:18:43.995645Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install xlsxwriter\n",
    "# ! pip install pympler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 23.097613327304835\n",
    "print(f'Format {num*100}%')\n",
    "print(f'Format {num*100:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"os\"></a>\n",
    "# Os\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "This module provides a portable way of using operating system dependent functionality.\n",
    "\n",
    "When running a python script you can use the following to extract path to where the script is being run:  \n",
    "`os.path.dirname(os.path.abspath(__file__))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()                                                      # get current path\n",
    "os.listdir()                                                     # list files and folders\n",
    "os.system('cp test.txt ../')                                     # run bash command (returns 0 for success, 1 for failure)\n",
    "os.mkdir('test_folder')                                          # create directory\n",
    "os.rmdir('test_folder')                                          # delete directory\n",
    "os.path.abspath('.')                                             # get full path to given location\n",
    "os.path.dirname('.')                                             # get full path up to previous fold of given path\n",
    "os.path.join('folder', 'file')                                   # create path by joining subpaths\n",
    "os.path.realpath('example_ml.ipynb')                             # get the real path of file\n",
    "os.path.getsize('example_ml.ipynb')                              # get the size in bytes of a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"sys\"></a>\n",
    "# Sys\n",
    "\n",
    "[Contents](#contents)\n",
    "\n",
    "This module provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof('example_python.ipynb')                            # returns byte size of obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that `sys.getsizeof` returns the size in Bytes of a python object whereas `os.path.getsize` returns the size in Bytes of a file or folder.\\\n",
    "Furthermore `sys.getsizeof` only measures the size of a an object itself without measuring the size of its internal or nested  elements.\\\n",
    "To get the full size of a python object you can use `asizeof` form `pympler` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file\n",
    "print(f'OS:      {os.path.getsize(\"example_ml.ipynb\")}')         # get the size in bytes of the file\n",
    "print(f'SYS:     {sys.getsizeof(\"example_ml.ipynb\")}')           # get the size in bytes of the string object\n",
    "print(f'Pympler: {asizeof.asizeof(\"example_ml.ipynb\")}')         # get the size in bytes of the string object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object\n",
    "dd = {'a':1, 'b':2, 'c':3}\n",
    "print(f'SYS:     {sys.getsizeof(dd)}')                           # only measures the memory consumed by the dictionary itself\n",
    "print(f'Pympler: {asizeof.asizeof(dd)}')                         # asizeof includes the sizes of nested objects in its calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you chose the size method that is most suitable to your use-case then you can take advantage of this function to print size in human readable format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_size(num, suffix='B'):\n",
    "    for unit in ('', 'K', 'M', 'G', 'T', 'P', 'E', 'Z'):\n",
    "        if abs(num) < 1024.0:\n",
    "            return f'{num:3.1f}{unit}{suffix}'\n",
    "        num /= 1024.0\n",
    "\n",
    "    return f'{num:.1f}Y{suffix}'\n",
    "    \n",
    "format_size(os.path.getsize('example_ml.ipynb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"pdb\"></a>\n",
    "# Pdb\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "The module pdb defines an interactive source code debugger for Python programs.\n",
    "It supports setting (conditional) breakpoints and single stepping at the source line level, inspection of stack frames, source code listing, and evaluation of arbitrary Python code in the context of any stack frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"string\"></a>\n",
    "# String\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T10:10:54.197696Z",
     "start_time": "2022-08-23T10:10:54.184352Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "ss = 'Hy there, WHAT was- that? Sad.nEss'\n",
    "' '.join(ss.translate(str.maketrans(string.punctuation, ' ' * len(string.punctuation))).title().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"regex\"></a>\n",
    "# Regex\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "- character classes\n",
    "    - `.` matches whatever character except from a newline  \n",
    "    - `\\w`, `\\d`, `\\s` match respectively word, digit, whitespace\n",
    "    - `\\W`, `\\D`, `\\S` match respectively not word, digit, whitespace\n",
    "    - `[abc]` match any of a, b, or c\n",
    "    - `[^abc]` match not a, b, or c\n",
    "    - `[a-g]` match any character between a & g\n",
    "- anchors\n",
    "    - `^abc`, `abc$` match respectively the start / end of the string\n",
    "    - `\\b`, `\\B` match respectively word, not-word boundary\n",
    "- escape characters\n",
    "    - `\\.`, `\\*`, `\\\\` are escaped special characters\n",
    "    - `\\t`, `\\n`, `\\r` refer to tab, linefeed and carriage return\n",
    "- groups & lookaround\n",
    "    - `(abc)` is a capture group meaning that returns the string that matches the pattern insided the parenthesis \n",
    "    - `\\1` is a backreference to group #1\n",
    "    - `(?:abc)` is a non-capturing group\n",
    "    - `(?=abc)`, `(?!abc)` are positive and negative lookahead\n",
    "    - `(?<=a)b`, `(?<!a)b` are positive and negative lookbehind\n",
    "- quantifiers & alternation\n",
    "    - `a*`, `a+`, `a?` match respectively 0 or more, 1 or more, 0 or 1 of the specified pattern\n",
    "    - `a{5}`, `a{2,}` match respectively exactly five, two or more of the specified pattern\n",
    "    - `a{1,3}` match between one & three occurrences of the pattern\n",
    "    - `a+?a{2,}?` match match as few as possible occurrences\n",
    "    - `ab|cd` match either of the two patterns\n",
    "    \n",
    "**Note** that lookahead and lookbehind require fixed-width pattern\n",
    "\n",
    "**References**\n",
    "- https://regexr.com/\n",
    "- https://regex101.com/\n",
    "- https://www.w3schools.com/python/python_regex.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting** can be done with the `re.split(pattern, string)` method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split function\n",
    "ss = 'one two 3.4 5,6 seven.eight nine,ten'\n",
    "re.split('\\s|(?<!\\d)[,.](?!\\d)', ss)                             # split string by characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Searching** can be done with the `re.search(pattern, string)` method.  \n",
    "This finds all occurrences of search pattern insinde the input string.\n",
    "\n",
    "You can use `group()` method to retrieve a specific match from the search output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search function\n",
    "path = 'gs://my-bucket/common/feeds/maps/year=2021/month=5/day=19/'\n",
    "re.search('gs://([^/]+)/(.+)/', path)                            # return the match object\n",
    "re.search('gs://([^/]+)/(.+)/', path).group(2)                   # return the second match element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing** and **removing** can be done with the `re.sub(pattern, replace, string)` method.\n",
    "\n",
    "**Note** that you must not pass escape characters as `replace` argument to `re.sub()` method. Instead use exact characters (i.e. `' '` instead of `'\\s'` or `','` instead of `'\\,'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace function\n",
    "path = 'gs://my-bucket/common/feeds/maps/year=2021/month=5/day=19/'\n",
    "re.sub(r'/year=[0-9]{4}$', '', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"rnd\"></a>\n",
    "# Random\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "This module implements **pseudo-random** number generators for various distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T08:59:47.735477Z",
     "start_time": "2022-08-23T08:59:47.717330Z"
    }
   },
   "outputs": [],
   "source": [
    "rnd.seed()                                                       # initialize the random number generator\n",
    "rnd.random()                                                     # generate random float between 0 and 1\n",
    "rnd.randint(0,5)                                                 # generate random integer between given numbers\n",
    "rnd.choice([1,3,5,7,9])                                          # extract random sample from sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"time\"></a>\n",
    "# Time\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "This module provides various time-related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current time \n",
    "tz = pytz.timezone('Europe/Rome')\n",
    "now = dt.datetime.now(tz)\n",
    "now.strftime('%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# execution time in seconds\n",
    "print(f'Execution time: {time.time() - start_time} seconds')\n",
    "\n",
    "# execution time in readable format\n",
    "print(f'Execution time: {dt.timedelta(seconds=time.time() - start_time)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"datetime\"></a>\n",
    "# Datetime\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "The datetime module supplies classes for manipulating dates and times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"timeobj\"></a>\n",
    "## time objects\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "A time object represents a (local) time of day, independent of any particular day, and subject to adjustment via a tzinfo object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = dt.time(3, 45, 12)                                        # create custom time variable\n",
    "hour, minute, second = time.hour, time.minute, time.second       # access time elements\n",
    "time_repl = time.replace(hour=5, second=30)                      # replace values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"dateobj\"></a>\n",
    "## date objects\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "A date object represents a date (year, month and day) in an idealized calendar, the current Gregorian calendar indefinitely extended in both directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = dt.date.today()                                          # get today's date variable\n",
    "date = dt.date(2021, 1, 1)                                       # create custom date\n",
    "year, month, day = date.year, date.month, date.day               # access elements\n",
    "date.weekday()                                                   # get day of the way as integer where monday is 0 and sunday is 6\n",
    "today.strftime('%Y%m%d')                                         # strftime: this means string formatter and will format a data format to string\n",
    "today.isoformat()                                                # isoformat: converts a date to the ISO 8601 format that is YYYY-MM-DD\n",
    "date + dt.timedelta(days=180)                                    # add / remove days to date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"datetimeobj\"></a>\n",
    "## datetime objects\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "A datetime object is a single object containing all the information from a date object and a time object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = dt.datetime.now()                                          # get current datetime variable\n",
    "ds = dt.datetime(2021, 1, 1)                                     # create custom datetime\n",
    "hour, minute, second = ds.hour, ds.minute, ds.second             # access elements\n",
    "weekday = ds.weekday()                                           # get day of the way as integer where monday is 0 and sunday is 6\n",
    "date = ds.date()                                                 # convert datetime to date object\n",
    "ds.replace(month=3, minute=16)                                   # replace values\n",
    "dt.datetime.strptime('2019-08-09 01:01:01', '%Y-%m-%d %H:%M:%S') # strptime: this means string parser and will convert a string to datetime\n",
    "ds.strftime('%Y-%m-%d %H:%M:%S')                                 # strftime: this means string formatter and will format a data format to string and can be used to print datetime in readable format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"dateutil\"></a>\n",
    "# Dateutil\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "Dateutil provides a useful method to compute date differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the different behavior using month or months\n",
    "date = dt.date(2021, 1, 1)                                       # create custom date\n",
    "date - relativedelta(months=2)                                   # removes 2 months from date\n",
    "date - relativedelta(month=2)                                    # replaces month 2 to current date's month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"zipfile\"></a>\n",
    "# Zipfile\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "The ZIP file format is a common archive and compression standard. This module provides tools to create, read, write, append, and list a ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('sampleDir.zip', 'r') as zip_file:\n",
    "    zip_file.extractall()                                        # extract all the contents of zip file in current directory\n",
    "    zip_file.extractall('target_folder')                         # extract all the contents of zip file in different directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only extract files with specified pattern from zip folder to target folder\n",
    "with zipfile.ZipFile('sampleDir.zip', 'r') as zip_file:\n",
    "    filenames_list = zipObj.namelist()\n",
    "    for filename in filenames_list:\n",
    "        if filename.endswith('.csv'):\n",
    "            zip_file.extract(filename, 'target_folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"argparse\"></a>\n",
    "# Argparse\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "The argparse module makes it easy to write user-friendly command-line interfaces.\\\n",
    "The program defines what arguments it requires, and argparse will figure out how to parse those out of sys.argv. The argparse module also automatically generates help and usage messages. The module will also issue errors when users give the program invalid arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Revenue estimation for GNLC')\n",
    "# positional argument\n",
    "parser.add_argument('month', help='GNLC date in YYYYMM format', required=True)\n",
    "# option argument that takes a value\n",
    "parser.add_argument('-c', '--campaign', help='GNLC campaign', required=False, choices=['SME', 'SOHO', 'OneNet'], default='SME')\n",
    "parser.add_argument('--force-train', action='store_true', help='Force model train')\n",
    "\n",
    "# parse some argument list\n",
    "args = parser.parse_args()\n",
    "gnlc_date = args.month\n",
    "campaign = args.campaign\n",
    "force_train = args.force_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Revenue estimation for GNLC parser')\n",
    "\n",
    "# create subparsers\n",
    "subparsers = parser.add_subparsers(help='Sub-parsers help')\n",
    "\n",
    "# create the parser for the \"full\" command\n",
    "parser_full = subparsers.add_parser('full', help='Full command help')\n",
    "parser_full.add_argument('month', type=str, help='GNLC date in YYYYMM format')\n",
    "\n",
    "# create the parser for the \"incr\" command\n",
    "parser_incr = subparsers.add_parser('incr', help='Incremental command help')\n",
    "parser_incr.add_argument('-c', help='GNLC campaign')\n",
    "\n",
    "# parse some argument list\n",
    "parser.parse_args(['full', '202209'])\n",
    "parser.parse_args(['incr', '-c', '2023q3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"subproc\"></a>\n",
    "# Subprocess\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "The subprocess module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f'gsutil ls -r gs://{bucket}/{prefix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run should be used as the default method\n",
    "p = subprocess.run(\n",
    "    cmd,\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT)\n",
    "\n",
    "# Popen can be used for edge cases when more control is needed\n",
    "p = subprocess.Popen(\n",
    "    cmd,\n",
    "    shell=True,\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.STDOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = p.stdout.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"multiproc\"></a>\n",
    "# Multiprocessing\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "multiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency, effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both POSIX and Windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute code in parallel, you first need to wrap the code you want to run in parallel in a function and then set up a pool of cores that can run the code with the `Pool` class.  \n",
    "The `Pool` class can be initialized with the number of available cores and then it coordinates them to run the same code in parallel with the `map` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap epub reader method to a functions that can be mapped\n",
    "def read_epub(filename_):\n",
    "    epub_content = epub.read_epub(os.path.join(epubs_path, filename_))\n",
    "    content = ' '.join([BeautifulSoup(item.content, 'html.parser').get_text() for item in epub_content.get_items_of_type(ebooklib.ITEM_DOCUMENT)])\n",
    "    for key, val in special_chars.items():\n",
    "        content = content.replace(key, val)\n",
    "    content = re.sub(r\"([A-Z])([a-zA-Z]+)\", lambda m: m.group(1) + m.group(2).lower(), content)\n",
    "    content = re.sub('\\n+', '. ', content)\n",
    "    return pd.DataFrame(data=[[filename_.split('.')[0], content]], columns=['isbn', 'text'])\n",
    "\n",
    "\n",
    "data = []\n",
    "schema = StructType([\n",
    "    StructField('isbn', StringType(), False),\n",
    "    StructField('text', StringType(), False)\n",
    "])\n",
    "\n",
    "\n",
    "# get a list of file names\n",
    "available_books_list = os.listdir(epubs_path)\n",
    "books_list = [isbn for isbn in isbn_list if isbn in available_books_list] \n",
    "\n",
    "# set up your pool\n",
    "with multiprocessing.Pool(processes=8) as pool:\n",
    "    # have your pool map the file names to dataframes\n",
    "    df_list = pool.map(read_epub, books_list)\n",
    "    # reduce the list of dataframes to a single dataframe\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"unittest\"></a>\n",
    "# Unittest\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "The unittest unit testing framework was originally inspired by JUnit and has a similar flavor as major unit testing frameworks in other languages. It supports test automation, sharing of setup and shutdown code for tests, aggregation of tests into collections, and independence of the tests from the reporting framework\n",
    "\n",
    "**References**\n",
    "- https://towardsdatascience.com/how-to-easily-and-confidently-implement-unit-tests-in-python-cad48d91ab74\n",
    "- https://www.datacamp.com/community/tutorials/unit-testing-python![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first define a custom function\n",
    "def cuboid_volume(l):\n",
    "    if type(l) not in [int, float]:\n",
    "        raise TypeError('ERROR! Input length is not valid, please specify an integer of float value')\n",
    "    return (l*l*l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then test the custom function with different kind of inputs\n",
    "length = [2,1.1, -2.5, 2j, 'two', False]\n",
    "\n",
    "for i in range(len(length)):\n",
    "    print (f'The volume of cuboid: {cuboid_volume(length[i])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing Python scripts, test runner must be a Python file called `test_<module_to_be_tested>.py` and placed in the `tests` folder.\n",
    "The file must store a test suite similar to the following one and you need to provide your test runner with the following lines of code in order to execute the tests.\n",
    "\n",
    "```\n",
    "if __name__ == '__main__':\n",
    "    unittest.main()\n",
    "```\n",
    "\n",
    "Finally, the test runner can be executed from your working environment as follows:\n",
    "\n",
    "`python -m unittest tests/test_<module_to_be_tested>.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCuboid(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        # setUp() mehtod is run before any test\n",
    "        # if you need to define or load some data you can do it inside the setUp() method\n",
    "        pass\n",
    "        \n",
    "    def tearDown(self):\n",
    "        # tearDown() wil be run if setUp() succeeded, careless of whether the test methods succeeded or not\n",
    "        # if your test writes some output then you can use tearDown() to delete it\n",
    "        pass\n",
    "        \n",
    "    def test_volume(self):\n",
    "        self.assertAlmostEqual(cuboid_volume(2), 8)\n",
    "        self.assertAlmostEqual(cuboid_volume(1), 1)\n",
    "        self.assertAlmostEqual(cuboid_volume(0), 0)\n",
    "        self.assertAlmostEqual(cuboid_volume(5.5), 166.375)\n",
    "        \n",
    "    def test_input_values(self):\n",
    "        self.assertRaises(TypeError, cuboid_volume, False)\n",
    "        self.assertRaises(TypeError, cuboid_volume, 'String')\n",
    "        self.assertRaises(TypeError, cuboid_volume, ['el1', 'el2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"ab\"></a>\n",
    "# A/B Tests\n",
    "\n",
    "[Return to Contents](#contents)\n",
    "\n",
    "An A/B Test is a randomised experiment containing two groups, A and B that receive different experiences. Within an A/B Test, we look to understand and measure the response of each group.\n",
    "\n",
    "Assume you are an on-line commerce business and wish to make changes to the current product page. The current conversion rate is 13% on average and you would be happy with an increase of 2%.\n",
    "\n",
    "First you must formulate a hypotesis before starting to test. This will make sure that the interpretation of the result is correct as well as rigorous. The **null hypotesis** usually is the one stating that there is no statistical difference when comparing the test result with the current situation ($H_{0}: p=p_{0}$). Then you can pick one-tailed ($H_{a}: p>p_{0}$) or two-tailed tests ($H_{a}: p\\neq p_{0}$) where\n",
    "- $H_{0}$ is the null hypotesis\n",
    "- $H_{a}$ il the alternate hypotesis\n",
    "- $p_{0}$ is the conversion rate of the old design\n",
    "- $p$ is the conversion rate of the new design\n",
    "\n",
    "Then you have to set a **confidence level**, for example 95% which leads to considering a **significance level** $\\alpha = 0.05$.\n",
    "\n",
    "Next, you have to choose a **sample size**. The number of people (or user session) we decide to capture in each group will have an effect on the precision of our estimated conversion rates: the larger the sample size, the more precise our estimates. The sample size can be estimated through the **power analysis** that depends on:\n",
    "- significance level ($\\alpha$)\n",
    "- **power of the test** ($1-\\beta$): this represents the probability of finding a statistical difference between the groups is a test when a difference is actually present. It is usually set at 0.8 by convention\n",
    "- **effect size** or **detectable effect**: how big of a difference we expect there to be berween the conversion rates\n",
    "\n",
    "Effect size and sample size can be estimated in Python with the support of `statsmodels` library.  \n",
    "**Note** that the returned sample size is the number of observations you need for each group in order for the experiment to be statistically significant.\n",
    "\n",
    "Finally, you can draw results of your test. Since the sample size is large enough you can use normal approximation to calculate the $p$-value, that is z-test. Again, this can be easily be performed in Python through the `statsmodels` library.\n",
    "\n",
    "**Note**\n",
    "- $\\alpha$: significance level, false positive rate, type I error (in how many cases we reject null when we should not)\n",
    "- $\\beta$: false negative rate, type II error (in how many cases we fail to reject null when we should)\n",
    "- power: true positive rate, $1-\\beta$\n",
    "- $1-\\alpha$: true negative rate\n",
    "\n",
    "**References**\n",
    "- https://towardsdatascience.com/ab-testing-with-python-e5964dd66143\n",
    "- https://towardsdatascience.com/the-power-of-a-b-testing-3387c04a14e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.api import proportion_effectsize, NormalIndPower\n",
    "from statsmodels.stats.proportion import proportions_ztest, proportion_confint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate required sample size\n",
    "effect_size = proportion_effectsize(0.13, 0.15)\n",
    "sample_size = NormalIndPower().solve_power(\n",
    "    effect_size, \n",
    "    power=0.8, \n",
    "    alpha=0.05, \n",
    "    ratio=1\n",
    ")\n",
    "sample_size = ceil(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T08:31:09.593883Z",
     "start_time": "2022-10-04T08:31:08.742350Z"
    }
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "root_path = 'C:\\\\Users\\\\pgreselin\\\\OneDrive\\\\Python'\n",
    "data = pd.read_csv(os.path.join(root_path, 'Dati', 'ab_test.csv'))\n",
    "print(f'{len(data)} test results')\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T08:31:09.777713Z",
     "start_time": "2022-10-04T08:31:09.598607Z"
    }
   },
   "outputs": [],
   "source": [
    "# make sure there are no users that have been recorded multiple times\n",
    "session_counts = data['user_id'].value_counts(ascending=False)\n",
    "multi_users = session_counts[session_counts > 1].count()\n",
    "print(f'There are {multi_users} users that appear multiple times in the dataset')\n",
    "\n",
    "users_to_drop = session_counts[session_counts > 1].index\n",
    "data = data[~data['user_id'].isin(users_to_drop)]\n",
    "print(f'The updated dataset now has {len(data)} observations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-04T08:31:36.126598Z",
     "start_time": "2022-10-04T08:31:35.945389Z"
    }
   },
   "outputs": [],
   "source": [
    "# sampling data\n",
    "sample_size = 4720\n",
    "control_sample = data[data['group'] == 'control'].sample(n=sample_size, random_state=22)\n",
    "treatment_sample = data[data['group'] == 'treatment'].sample(n=sample_size, random_state=22)\n",
    "\n",
    "ab_test = pd.concat([control_sample, treatment_sample], axis=0)\n",
    "ab_test.reset_index(drop=True, inplace=True)\n",
    "print(f'Considering {len(ab_test)} observations for A/B test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the hypotesis\n",
    "control_results = ab_test[ab_test['group'] == 'control']['converted']\n",
    "treatment_results = ab_test[ab_test['group'] == 'treatment']['converted']\n",
    "\n",
    "n_con = control_results.count()\n",
    "n_treat = treatment_results.count()\n",
    "successes = [control_results.sum(), treatment_results.sum()]\n",
    "nobs = [n_con, n_treat]\n",
    "\n",
    "z_stat, pval = proportions_ztest(successes, nobs=nobs)\n",
    "(lower_con, lower_treat), (upper_con, upper_treat) = proportion_confint(successes, nobs=nobs, alpha=0.05)\n",
    "\n",
    "print(f'z statistic: {z_stat:.2f}')\n",
    "print(f'p-value: {pval:.3f}')\n",
    "print(f'ci 95% for control group: [{lower_con:.3f}, {upper_con:.3f}]')\n",
    "print(f'ci 95% for treatment group: [{lower_treat:.3f}, {upper_treat:.3f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"error\"></a>\n",
    "# Errors\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: write me...\n",
    "try:\n",
    "    # some code...\n",
    "except:\n",
    "    # optional block\n",
    "    # handling of exception (if required)\n",
    "else:\n",
    "    # some code...\n",
    "    # execute if no exception\n",
    "finally:\n",
    "    # some code...\n",
    "    # always executed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"data\"></a>\n",
    "# Data types\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"set\"></a>\n",
    "### set\n",
    "\n",
    "A set is a collection of elements which is **unordered**, **unchangeable**, and **unindexed**.\n",
    "\n",
    "Note that being a set unordered, set objects do not support indexing!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = {'pietro', 'luigi', 'mario', 'luigi'}\n",
    "s2 = {'mario', 'bowser', 'sissy'}\n",
    "\n",
    "\n",
    "len(s)                                                           # length of set\n",
    "s.add('giulio')                                                  # add / remove elements to a set\n",
    "s.remove('mario')                                                # remove: remove a specifi element from a set\n",
    "s.pop()                                                          # pop: removes a random element from a set\n",
    "s.intersection(s2)                                               # set intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"list\"></a>\n",
    "### list\n",
    "\n",
    "A list is a collection of elements which is **ordered**, **changeable**, and **allow duplicate values**.\n",
    "\n",
    "**Ordered** means that the items have a defined order, and that order will not change.\n",
    "Elements of ordered collections can be accessed by their indexes in the following manner:\n",
    "```\n",
    "l = ['pietro', 'luigi', 'mario']\n",
    "l[2]\n",
    ">>> 'mario'\n",
    "```\n",
    "\n",
    "**Changeable** means that user can change, add, and remove items in a list after it has been created.\n",
    "```\n",
    "l += ['domenico']\n",
    "l[1] = 'filippo'\n",
    ">>> ['pietro', 'filippo', 'mario']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['pietro', 'luigi', 'mario']\n",
    "l2 = ['mario', 'sissy', 'bowser']\n",
    "\n",
    "len(l)                                                           # length of list\n",
    "l[1]                                                             # accessing elements\n",
    "l[:2], l[2:]                                                     # slice of list\n",
    "\n",
    "# sorting of list\n",
    "sorted(l, reverse=False)                                         # sorting of list in ascending / descending order\n",
    "l.sort(), l.sort(reverse=False)                                  # inplace sorting of list in ascending / descending order\n",
    "l.reverse()                                                      # reverse list\n",
    "l[::-1]                                                          # this is an alternative way to reverse a list, basically it lists elements from the last to the first\n",
    "\n",
    "# find elements in list\n",
    "min(l), max(l)                                                   # find min / max\n",
    "l.index('pietro')                                                # find index of element\n",
    "np.max(l), np.min(l)                                             # find min / max in numpy\n",
    "np.argmax(l), np.argmin(l)                                       # find argmin / argmax\n",
    "\n",
    "# adding / removing elements to list\n",
    "l.append('franco')                                               # append a single element at the end of the list\n",
    "l.insert('peppe', 2)                                             # insert a single element at a given position in the list\n",
    "l.remove('luigi')                                                # remove a specific element from a list (if multiple occurrences, only the first one is removed)\n",
    "l.pop, ll.pop(1)                                                 # remove an element from any position in the list (by default the last one)\n",
    "l += ['jhon', 'silvia']                                          # concatenate two lists into one\n",
    "\n",
    "# filtering list\n",
    "filtered(lambda x: x%5 == 0 and x%3 == 0, l)\n",
    "\n",
    "# list intersection\n",
    "# note that there is no method to perform list intersection directly, you have to use sets\n",
    "set(l).intersection(l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list comprehension\n",
    "\n",
    "List comprehension is a compact and elegant way to create a list from existing lists.  \n",
    "It has a simple and short inline sintax that allows not to declare any variable and for this reason it is usually faster to be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_list = [num for num in range(20) if num % 2 == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"tuple\"></a>\n",
    "### tuple\n",
    "\n",
    "A tuple is a collection of elements which is **ordered**, **unchangeable**, and **allow duplicate values**.\n",
    "\n",
    "If you try to change tuple's value then Python will throw TypeError\n",
    "```\n",
    "t = ('pietro', 'greselin', 23)\n",
    "t[2] = 26\n",
    ">>> TypeError: 'tuple' object does not support item assignment\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ('pietro', 'greselin', 23)\n",
    "\n",
    "len(t)                                                           # length of tuple\n",
    "t[1]                                                             # accessing elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tuples\n",
    "tup_list = [('pietro', 23), ('gino', 27), ('edo', 15), ('pietro', 31)]\n",
    "\n",
    "# flatten list of tuples\n",
    "list_flat = [tag for sublist in tup_list for tag in sublist]\n",
    "\n",
    "# sort inplace list of tuples by given element\n",
    "# by default ascending sort, you can change it using reverse=True\n",
    "tup_list.sort(key=lambda tup: tup[1], reverse=True)\n",
    "\n",
    "# find min / max in list of tuples\n",
    "# the method itemgetter(n) will look for the min / max over the n-th coordinate\n",
    "# REMEMBER this only works if the list has been previously sorted by the element you will group by on \n",
    "tup_list.sort(key=lambda tup: tup[1])\n",
    "max(tup_list, key=itemgetter(1))\n",
    "\n",
    "# aggregate list of tuples by given element\n",
    "# REMEMBER this only works if the list has been previously sorted by the element you will group by on \n",
    "tup_list.sort(key=lambda tup: tup[0])\n",
    "[max(v, key=itemgetter(1)) for k, v in groupby(tup_list, itemgetter(0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"dict\"></a>\n",
    "### dictionary\n",
    "\n",
    "A dictionary is a collection of key:value pairs which is **ordered**, **changeable** and **do not allow duplicates**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'name': 'pietro', 'surname': 'greselin', 'age': 23}\n",
    "\n",
    "# accessing elements\n",
    "d.keys(), d.values(), d.items()\n",
    "\n",
    "# sort dictionary in ascending/descending order by key or value\n",
    "dict(sorted(d.items(), key=itemgetter(1), reverse=True))\n",
    "{k: v for k, v in sorted(d.items(), key=lambda item: item[1])}\n",
    "\n",
    "# get maximum value from a dictionary\n",
    "max(d.values())\n",
    "# get key corrisponding to maximum value from a dictionary\n",
    "max(d.items(), key=itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dictionary comprehension\n",
    "\n",
    "Similar to list comprehension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_dict = {n: n**2 for n in range(5)}\n",
    "\n",
    "# it works also with nested dictionaries\n",
    "d = {\n",
    "    'LIGURIA': {\n",
    "        'IMPERIA': {\n",
    "            'popolazione': 1234,\n",
    "            'superficie': 2345,\n",
    "            'densita': 0.5,\n",
    "        },\n",
    "        'GENOVA': {\n",
    "            'popolazione': 63256,\n",
    "            'superficie': 1432,\n",
    "            'densita': 2.3,\n",
    "        }\n",
    "    },\n",
    "    'UMBRIA': {\n",
    "        'PERUGIA': {\n",
    "            'popolazione': 5728,\n",
    "            'superficie': 1346,\n",
    "            'densita': 4,\n",
    "        },\n",
    "        'TERNI': {\n",
    "            'popolazione': 125,\n",
    "            'superficie': 8548,\n",
    "            'densita': 0.1,\n",
    "        }\n",
    "    },\n",
    "}\n",
    "{f'{k0} - {k1}': v2 for k0, v0 in d.items() for k1, v1 in v0.items() for k2, v2 in v1.items() if k2 == 'popolazione'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"fnc\"></a>\n",
    "# Functions\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorators\n",
    "\n",
    "class Mathematics:\n",
    "\n",
    "    @staticmethod\n",
    "    def addNumbers(x, y):\n",
    "        return x + y\n",
    "\n",
    "# create addNumbers static method\n",
    "#Mathematics.addNumbers = staticmethod(Mathematics.addNumbers)\n",
    "\n",
    "print('The sum is:', Mathematics.addNumbers(5, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decorators\n",
    "\n",
    "class Maths:\n",
    "\n",
    "    def addNumbers(x, y):\n",
    "        return x + y\n",
    "\n",
    "print('The sum is:', Mathematics.addNumbers(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"obj\"></a>\n",
    "# Objects\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Employee():\n",
    "    'Common base class for all employees'\n",
    "    \n",
    "    # class variables\n",
    "    # they are variables whose value is shared among all instances of a this class\n",
    "    # class variables are defined before any object method\n",
    "    empCount = 0\n",
    "\n",
    "    # init method\n",
    "    # it's a class constructor or initialization method that Python calls when you create a new instance of this class\n",
    "    # it is used to define object attributes\n",
    "    def __init__(self, name, salary):\n",
    "        self.name = name\n",
    "        self.salary = salary\n",
    "        Employee.empCount += 1\n",
    "    \n",
    "    # class methods\n",
    "    # other class methods are defined as normal functions inside the object\n",
    "    # their first parameter is self which points to the instance and allows to access attributes and other methods on the same object\n",
    "    def displayCount(self):\n",
    "        print f'Total Employee {Employee.empCount}'\n",
    "\n",
    "    def displayEmployee(self):\n",
    "        print f'Name : {self.name}, Salary: {self.salary}'\n",
    "        \n",
    "# object instance\n",
    "emp1 = Employee('Zara', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inheritance\n",
    "# TODO: write me..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classmethod and staticmethod\n",
    "class MyClass:\n",
    "    def method(self):\n",
    "        return f'instance method called {self}'\n",
    "\n",
    "    # classmethod do not accept a self parameter, instead it takes a cls parameter that points to the class (and not the object instance) when the method is called\n",
    "    # classmethods cannot modify object instance state, it can only modify class state that applies across all instances of the class\n",
    "    @classmethod\n",
    "    def classmethod(cls):\n",
    "        return f'class method called {cls}'\n",
    "\n",
    "    # staticmethod takes neither a self nor a cls parameter (but of course it's free to accept an arbitrary number of other parameters)\n",
    "    # it can neither modify object state nor class state and it's primarily a way to namespace your methods\n",
    "    @staticmethod\n",
    "    def staticmethod():\n",
    "        return 'static method called'\n",
    "    \n",
    "myclass = MyClass()\n",
    "print(myclass.method())\n",
    "print(myclass.classmethod())  # note classmethod doesnt have access to the <MyClass instance> object, but only to the <class MyClass> object\n",
    "print(myclass.staticmethod())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of object's methods and properties\n",
    "inspect.getmembers(table)                                        # retrieve list of the members of an object\n",
    "inspect.getmembers(table, predicate=inspect.ismethod)            # get list of methods of an object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a name=\"io\"></a>\n",
    "# I/O\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"create\"></a>\n",
    "## create\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_ = 'pietro'\n",
    "list_ = ['pietro', 'luigi', 'mario']\n",
    "set_ = {'pietro', 'luigi', 'mario', 'luigi'}\n",
    "tuple_ = ('pietro', 'greselin', 23)\n",
    "dict_ = {'name': 'pietro', 'surname': 'greselin', 'age': 23}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"write\"></a>\n",
    "## write\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write string to txt file\n",
    "with open('string.txt', 'w') as txt_file:\n",
    "    txt_file.write(string)\n",
    "txt_file.close()\n",
    "\n",
    "# write list to txt file\n",
    "with open('list.txt', 'w') as txt_file:\n",
    "    for el in el_list:\n",
    "        txt_file.write(el + '\\n')\n",
    "txt_file.close()\n",
    "\n",
    "# write dictionary to csv file\n",
    "with open('dict.csv', 'w') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    for key, value in dictionary.items():\n",
    "        writer.writerow([key, value])\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"read\"></a>\n",
    "## read\n",
    "\n",
    "[Return to Contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read list from txt\n",
    "with open('list.txt', 'r') as txt_file:\n",
    "    content = txt_file.read().split('\\n')\n",
    "    \n",
    "# read dictionary from csv\n",
    "# dictionary is read as k,v\n",
    "import csv\n",
    "with open('dict.csv', 'r') as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    mydict = {rows[0]: rows[1] for rows in reader}\n",
    "    \n",
    "# read dictionary from yaml\n",
    "import yaml\n",
    "with open('dict.yaml'), 'r') as yaml_file:\n",
    "    mydict = yaml.safe_load(yaml_file)\n",
    "    \n",
    "# read json or other formats\n",
    "from joblib import load\n",
    "with open(input_path, 'r') as f:\n",
    "    file = load(f)\n",
    "    json_file = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# special characters\n",
    "# when reading input file with special characters then those character can be encoded, to avoid it use the following syntax\n",
    "with open('list.txt', encoding='utf-8') as txt_file:\n",
    "    lines = txt_file.readlines()\n",
    "    for line in lines:\n",
    "        split_line = line.strip().split(' ; ')\n",
    "        dizio_gen[split_line[0]] = split_line[1]\n",
    "\n",
    "# when reading input file the following error coudl be retrieved:   UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe0\n",
    "# with txt file\n",
    "with open('list.txt', 'r', encoding='ISO-8859-1') as txt_file:\n",
    "    content = txt_file.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
